{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini project 1: air quality in U.S. cities\n",
    "\n",
    "In a way, this project is simple: you are given some data on air quality in U.S. metropolitan areas over time together with several questions of interest, and your objective is to answer the questions.\n",
    "\n",
    "However, unlike the homeworks and labs, there is no explicit instruction provided about *how* to answer the questions or where exactly to begin. Thus, you will need to discern for yourself how to manipulate and summarize the data in order to answer the questions of interest, and you will need to write your own codes from scratch to obtain results. It is recommended that you examine the data, consider the questions, and plan a rough approach before you begin doing any computations.\n",
    "\n",
    "You have some latitude for creativity: **although there are accurate answers to each question** -- namely, those that are consistent with the data -- **there is no singularly correct answer**. Most students will perform similar operations and obtain similar answers, but there's no specific result that must be considered to answer the questions accurately. As a result, your approaches and answers may differ from those of your classmates. If you choose to discuss your work with others, you may even find that disagreements prove to be fertile learning opportunities.\n",
    "\n",
    "The questions can be answered using computing skills taught in class so far and basic internet searches for domain background; for this project, you may wish to refer to HW1 and Lab1 for code examples and the [EPA website on PM pollution](https://www.epa.gov/pm-pollution) for background. However, you are also encouraged to refer to external resources (package documentation, vignettes, stackexchange, internet searches, etc.) as needed -- this may be an especially good idea if you find yourself thinking, 'it would be really handy to do X, but I haven't seen that in class anywhere'.\n",
    "\n",
    "The broader goal of these mini projects is to cultivate your problem-solving ability in an unstructured setting. Your work will be evaluated based on the following:\n",
    "- choice of method(s) used to answer questions;\n",
    "- clarity of presentation;\n",
    "- code style and documentation.\n",
    "\n",
    "Please write up your results separately from your codes; codes should be included at the end of the notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Dataset\n",
    "\n",
    "Merge the city information with the air quality data and tidy the dataset (see notes below). Write a brief description of the data.\n",
    "\n",
    "In your description, answer the following questions:\n",
    "\n",
    "- What is a CBSA (the geographic unit of measurement)?\n",
    "- How many CBSA's are included in the data?\n",
    "- In how many states and territories do the CBSA's reside? (*Hint: `str.split()`*)\n",
    "- In which years were data values recorded?\n",
    "- How many observations are recorded?\n",
    "- How many variables are measured?\n",
    "- Which variables are non-missing most of the time (*i.e.*, in at least 50% of instances)?\n",
    "- What is PM 2.5 and why is it important?\n",
    "\n",
    "Please write your description in narrative fashion; _**please do not list answers to the questions above one by one**_. A few brief paragraphs should suffice; please limit your data description to three paragraphs or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air quality data\n",
    "\n",
    "*A CBSA is a core based stastical area that represents the location of the obsevation, and there are 351 unique CBSA values across 86 different states/territories. Data values were recorded from 2000-2019, with the orginal data set containing 1134 observations. After cleaning up the data, there are actually 7020 observations across 13 different variables, including CBSA, City, State, Year, and 9 different pollution statistics. Many of the variables have a lot of missing values, with only O3-4th Max, PM2.5-98th Percentile, and PM2.5- Weighted Annual Mean having less than 50% missing.\n",
    "\n",
    "PM2.5 is particulate matter with a diameter of 2.5 micrometers. Its small size makes it extremely easy to inhale and can pose some serious health risks if it makes its way into your lungs or bloodstream.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Descriptive analysis\n",
    "\n",
    "Focus on the PM2.5 measurements that are non-missing most of the time. Answer each of the following questions in a brief paragraph or two. Your paragraph(s) should indicate both your answer and a description of how you obtained it; _**please do not include codes with your answers**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has PM 2.5 air pollution improved in the U.S. on the whole since 2000?\n",
    "\n",
    "Overall, PM 2.5 air pollution has improved, going from an average concentration of 13.06 in 2000 to 7.56 in 2019 across the US. I discerned this by grouping the PM 2.5 values by year and averaging them. Then, I created a data frame with the columns 'Year' and 'Average PM2.5', and observed the difference between the 2000 and 2019 values where I noticed a signifcant decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over time, has PM 2.5 pollution become more variable, less variable, or about equally variable from city to city in the U.S.?\n",
    "\n",
    "Over time, PM 2.5 pollution has become far less variable from city to city. Similarly to overall PM 2.5 pollution, I grouped the values by year and found the variance rather than the average. I looked at the values in another 19 x 2 data frame, where the variability between all of the cities/states in 2000 was 12.14 and 2.59 in 2019.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which state has seen the greatest improvement in PM 2.5 pollution over time? Which city has seen the greatest improvement?\n",
    "\n",
    "Portsmouth, OH was the city that had the most improvement in PM2.5 pollution from 2000-2019 with a decrease by 14.4 micrograms/cubic meter. The 'state' that had the greatest improvement was the Tennessee-Virginia (TN-VA) area with a decrease by 10.2 micrograms/cubic meter, but the most improved singular state was WYoming (WY) with a decrease by 8.94 micrograms /cubic meter.\n",
    "\n",
    "In order to obtained the city value, I took my unpivoted/unmeleted data set from the beginning of this project and dropped all of the clumns that were not needed. Then, I iterated through the rows of the data frame to get rid of any observations that weren't measuring the Weighted Annual Mean of PM2.5. I then created a new column to measure the difference of each observation from 2000 to 2019 and sorted the values from least to greatest. \n",
    "\n",
    "To obtain the state values, I took my new data set, grouped it by state, and then averaged all of the values for each observation. I then sorted by the difference value I created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a location with some meaning to you (e.g. hometown, family lives there, took a vacation there, etc.). Was that location in compliance with EPA primary standards as of the most recent measurement?\n",
    "\n",
    "At first, I wanted to do my hometown, San Jose, but there were no measurements for PM2.5-Weighted Annual Mean, so I went broader and chose San Francisco, and was able to find that, in 2019, San Francisco had a PM2.5 pollution of 7.0 micrograms/cubic meter, which is compliant with the EPA primary standard of 12.0 micrograms/cubic meter. I did this by going through my data set that I created to obtain the improvement values and looked for observations where the city contained the string 'San Francisco'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit: Imputation\n",
    "\n",
    "One strategy for filling in missing values ('imputation') is to use non-missing values to predict the missing ones; the success of this strategy depends in part on the strength of relationship between the variable(s) used as predictors of missing values. \n",
    "\n",
    "Identify one other pollutant that might be a good candidate for imputation based on the PM 2.5 measurements and explain why you selected the variable you did. Can you envision any potential pitfalls to this technique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Pollutant Statistic</th>\n",
       "      <th>CO-2nd Max</th>\n",
       "      <th>NO2-98th Percentile</th>\n",
       "      <th>NO2-Annual Mean</th>\n",
       "      <th>O3-4th Max</th>\n",
       "      <th>PM10-2nd Max</th>\n",
       "      <th>PM2.5-98th Percentile</th>\n",
       "      <th>PM2.5-Weighted Annual Mean</th>\n",
       "      <th>Pb-Max 3-Month Average</th>\n",
       "      <th>SO2-99th Percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBSA</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10100</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Aberdeen</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">SD</th>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pollutant Statistic        CO-2nd Max  NO2-98th Percentile  NO2-Annual Mean  \\\n",
       "CBSA  City     State Year                                                     \n",
       "10100 Aberdeen  SD   2000         NaN                  NaN              NaN   \n",
       "                     2001         NaN                  NaN              NaN   \n",
       "                     2002         NaN                  NaN              NaN   \n",
       "                     2003         NaN                  NaN              NaN   \n",
       "                     2004         NaN                  NaN              NaN   \n",
       "\n",
       "Pollutant Statistic        O3-4th Max  PM10-2nd Max  PM2.5-98th Percentile  \\\n",
       "CBSA  City     State Year                                                    \n",
       "10100 Aberdeen  SD   2000         NaN          50.0                   23.0   \n",
       "                     2001         NaN          58.0                   23.0   \n",
       "                     2002         NaN          59.0                   20.0   \n",
       "                     2003         NaN          66.0                   21.0   \n",
       "                     2004         NaN          39.0                   23.0   \n",
       "\n",
       "Pollutant Statistic        PM2.5-Weighted Annual Mean  Pb-Max 3-Month Average  \\\n",
       "CBSA  City     State Year                                                       \n",
       "10100 Aberdeen  SD   2000                         8.6                     NaN   \n",
       "                     2001                         8.6                     NaN   \n",
       "                     2002                         7.9                     NaN   \n",
       "                     2003                         8.4                     NaN   \n",
       "                     2004                         8.1                     NaN   \n",
       "\n",
       "Pollutant Statistic        SO2-99th Percentile  \n",
       "CBSA  City     State Year                       \n",
       "10100 Aberdeen  SD   2000                  NaN  \n",
       "                     2001                  NaN  \n",
       "                     2002                  NaN  \n",
       "                     2003                  NaN  \n",
       "                     2004                  NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# raw data\n",
    "air_raw = pd.read_csv('air-quality.csv')\n",
    "cbsa_info = pd.read_csv('cbsa-info.csv')\n",
    "\n",
    "## PART I\n",
    "#merge air and cbsa datasets, left join\n",
    "merged_data = pd.merge(air_raw, cbsa_info, how = 'left', on= 'CBSA')\n",
    "merged_data \n",
    "\n",
    "# split core based statistical area into city and state.\n",
    "data = merged_data.copy()\n",
    "cbsa_split = data['Core Based Statistical Area'].str.split(\n",
    "    r',', expand=True).rename(\n",
    "    columns = {0: 'City', 1: 'State'})\n",
    "data2 = cbsa_split.join(data).drop(\n",
    "    columns = 'Core Based Statistical Area')\n",
    "\n",
    "data3 =data2.copy()\n",
    "\n",
    "#number of unique territories\n",
    "unique_territories = []\n",
    "for i in data2['State']:\n",
    "    if i not in unique_territories:\n",
    "        unique_territories.append(i)\n",
    "len(unique_territories)  #86\n",
    "data2.head()\n",
    "#tidying!\n",
    "data2['Pollutant Statistic'] = data2[['Pollutant','Trend Statistic']].agg(\n",
    "    '-'.join, axis=1)\n",
    "data2 = data2.drop(\n",
    "    columns = ['Number of Trends Sites','Trend Statistic', 'Pollutant'], axis = 1\n",
    ").melt(\n",
    "    id_vars= ['CBSA', 'City', 'State', 'Pollutant Statistic'],\n",
    "    var_name = 'Year',\n",
    "    value_name = 'value'\n",
    ").pivot(\n",
    "    index = ['CBSA','City','State','Year'],\n",
    "    columns = ['Pollutant Statistic'],\n",
    "    values = 'value'\n",
    ")\n",
    "\n",
    "#look for missing variables\n",
    "data2.isna().mean()\n",
    "\n",
    "\n",
    "data2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Average PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>13.057944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>12.688318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>12.352336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>11.853271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>11.642056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>12.479439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>11.360748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>11.573364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>10.625234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>9.671028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.830374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.638318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.973364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>8.798598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.660748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>8.342523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>7.585047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.942991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>8.115421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>7.559813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Average PM2.5\n",
       "0   2000      13.057944\n",
       "1   2001      12.688318\n",
       "2   2002      12.352336\n",
       "3   2003      11.853271\n",
       "4   2004      11.642056\n",
       "5   2005      12.479439\n",
       "6   2006      11.360748\n",
       "7   2007      11.573364\n",
       "8   2008      10.625234\n",
       "9   2009       9.671028\n",
       "10  2010       9.830374\n",
       "11  2011       9.638318\n",
       "12  2012       8.973364\n",
       "13  2013       8.798598\n",
       "14  2014       8.660748\n",
       "15  2015       8.342523\n",
       "16  2016       7.585047\n",
       "17  2017       7.942991\n",
       "18  2018       8.115421\n",
       "19  2019       7.559813"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PART 2\n",
    "\n",
    "## change in PM2.5 across the US from 2000-2019\n",
    "\n",
    "average = data2.groupby('Year').mean()\n",
    "average.columns\n",
    "average_df = pd.DataFrame()\n",
    "average_df['Year'] = average.index.tolist()\n",
    "average_df['Average PM2.5'] = average['PM2.5-Weighted Annual Mean'].tolist()\n",
    "average_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Variance in PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>12.140758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>10.520849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>10.419126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>8.687290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>15.455406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005</td>\n",
       "      <td>12.588871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.537044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>9.238020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>6.172130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009</td>\n",
       "      <td>4.949204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010</td>\n",
       "      <td>5.762313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011</td>\n",
       "      <td>4.790074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>3.214452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.636477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>3.993663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>3.444991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>2.848132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>3.436453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>5.274738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>2.594528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Variance in PM2.5\n",
       "0   2000          12.140758\n",
       "1   2001          10.520849\n",
       "2   2002          10.419126\n",
       "3   2003           8.687290\n",
       "4   2004          15.455406\n",
       "5   2005          12.588871\n",
       "6   2006           7.537044\n",
       "7   2007           9.238020\n",
       "8   2008           6.172130\n",
       "9   2009           4.949204\n",
       "10  2010           5.762313\n",
       "11  2011           4.790074\n",
       "12  2012           3.214452\n",
       "13  2013           4.636477\n",
       "14  2014           3.993663\n",
       "15  2015           3.444991\n",
       "16  2016           2.848132\n",
       "17  2017           3.436453\n",
       "18  2018           5.274738\n",
       "19  2019           2.594528"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variability in PM2.5 over time (2000-2019)\n",
    "\n",
    "variance = data2.groupby('Year').var()\n",
    "variance.columns\n",
    "variance_df = pd.DataFrame()\n",
    "variance_df['Year'] = variance.index.tolist()\n",
    "variance_df['Variance in PM2.5'] = variance['PM2.5-Weighted Annual Mean'].tolist()\n",
    "variance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSA</th>\n",
       "      <th>2000</th>\n",
       "      <th>2019</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TN-VA</th>\n",
       "      <td>28700.0</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>-10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA-AL</th>\n",
       "      <td>17980.0</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV-KY-OH</th>\n",
       "      <td>26580.0</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-9.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN-GA</th>\n",
       "      <td>16860.0</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>-9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>25484.0</td>\n",
       "      <td>16.360000</td>\n",
       "      <td>7.420000</td>\n",
       "      <td>-8.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND-MN</th>\n",
       "      <td>22020.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>16880.0</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>37250.0</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>-1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM</th>\n",
       "      <td>20240.0</td>\n",
       "      <td>6.450000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR</th>\n",
       "      <td>27780.0</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CBSA       2000       2019  Difference\n",
       "State                                               \n",
       " TN-VA     28700.0  16.600000   6.400000      -10.20\n",
       " GA-AL     17980.0  18.100000   8.800000       -9.30\n",
       " WV-KY-OH  26580.0  16.800000   7.700000       -9.10\n",
       " TN-GA     16860.0  17.600000   8.600000       -9.00\n",
       " WV        25484.0  16.360000   7.420000       -8.94\n",
       "...            ...        ...        ...         ...\n",
       " ND-MN     22020.0   8.000000   6.500000       -1.50\n",
       " ND        16880.0   5.400000   3.900000       -1.50\n",
       " HI        37250.0   4.700000   3.550000       -1.15\n",
       " NM        20240.0   6.450000   5.450000       -1.00\n",
       " OR        27780.0  10.733333  11.333333        0.60\n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which city/state improved the most?\n",
    "#state\n",
    "data3_improve=data3.drop(columns = ['Number of Trends Sites','2001','2002',\n",
    "                                    '2003','2004','2005','2006',\n",
    "                                    '2007','2008','2009','2010','2011',\n",
    "                                    '2012','2013','2014','2015',\n",
    "                                    '2016','2017','2018']\n",
    "                                       )\n",
    "data3_improve.head()\n",
    "for index, row in data3_improve.iterrows():\n",
    "    if row['Pollutant'] != 'PM2.5' or row['Trend Statistic'] != 'Weighted Annual Mean':\n",
    "        data3_improve.drop(index, inplace = True)\n",
    "data3_improve.head()\n",
    "data3_improve['Difference'] = data3_improve['2019']-data3_improve['2000']\n",
    "data3_improve.sort_values(by = 'Difference') #most improved city is Portsmouth!\n",
    "\n",
    "data3_state =data3_improve.groupby('State').mean()\n",
    "data3_state.sort_values(by = 'Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>CBSA</th>\n",
       "      <th>Pollutant</th>\n",
       "      <th>Trend Statistic</th>\n",
       "      <th>2000</th>\n",
       "      <th>2019</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>San Francisco-Oakland-Hayward</td>\n",
       "      <td>CA</td>\n",
       "      <td>41860</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Weighted Annual Mean</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              City State   CBSA Pollutant  \\\n",
       "899  San Francisco-Oakland-Hayward    CA  41860     PM2.5   \n",
       "\n",
       "          Trend Statistic  2000  2019  Difference  \n",
       "899  Weighted Annual Mean  11.2   7.0        -4.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compliance with EPA standards, standard is 12 micrograms/ cubic meter\n",
    "#41940\n",
    "\n",
    "data3_improve[(data3_improve['City'].str.contains('San Francisco'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes on merging (keep at bottom of notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine datasets based on shared information, you can use the `pd.merge(A, B, how = ..., on = SHARED_COLS)` function, which will match the rows of `A` and `B` based on the shared columns `SHARED_COLS`. If `how = 'left'`, then only rows in `A` will be retained in the output (so `B` will be merged *to* `A`); conversely, if `how = 'right'`, then only rows in `B` will be retained in the output (so `A` will be merged *to* `B`).\n",
    "\n",
    "A simple example of the use of `pd.merge` is illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy data frames\n",
    "A = pd.DataFrame(\n",
    "    {'shared_col': ['a', 'b', 'c'], \n",
    "    'x1': [1, 2, 3], \n",
    "    'x2': [4, 5, 6]}\n",
    ")\n",
    "\n",
    "B = pd.DataFrame(\n",
    "    {'shared_col': ['a', 'b'], \n",
    "    'y1': [7, 8]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_col</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shared_col  x1  x2\n",
       "0          a   1   4\n",
       "1          b   2   5\n",
       "2          c   3   6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_col</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shared_col  y1\n",
       "0          a   7\n",
       "1          b   8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, if `A` and `B` are merged retaining the rows in `A`, notice that a missing value is input because `B` has no row where the shared column (on which the merging is done) has value `c`. In other words, the third row of `A` has no match in `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_col</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shared_col  x1  x2   y1\n",
       "0          a   1   4  7.0\n",
       "1          b   2   5  8.0\n",
       "2          c   3   6  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join\n",
    "pd.merge(A, B, how = 'left', on = 'shared_col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the direction of merging is reversed, and the row structure of `B` is dominant, then the third row of `A` is dropped altogether because it has no match in `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_col</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shared_col  x1  x2  y1\n",
       "0          a   1   4   7\n",
       "1          b   2   5   8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right join\n",
    "pd.merge(A, B, how = 'right', on = 'shared_col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission Checklist\n",
    "1. Save file to confirm all changes are on disk\n",
    "2. Run *Kernel > Restart & Run All* to execute all code from top to bottom\n",
    "3. Save file again to write any new output to disk\n",
    "4. Select *File > Download as > HTML*.\n",
    "5. Open in Google Chrome and print to PDF.\n",
    "6. Submit to Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
